### Технічне завдання на розробку та інтеграцію плагіну голосового асистента для текстового чату

**Назва проєкту**: Плагін голосового асистента з підтримкою Google STT/TTS + Gemini або Whisper + Ollama + gTTS/Bark

**Мета**: Розробити плагін для інтеграції в існуючий текстовий чат, який перетворить його на повноцінного голосового асистента з підтримкою розпізнавання мовлення (STT), обробки текстових запитів (LLM) і синтезу мовлення (TTS). Плагін матиме два режими: високої якості (Google STT/TTS + Gemini) та безкоштовний офлайн-режим (Whisper + Ollama + gTTS/Bark). Асистент працюватиме в режимі “завжди увімкнено”, реагуючи на голосові запити в реальному часі та імітуючи природну людську взаємодію.

-----

### 1. Загальні вимоги

**Цільовий функціонал**:

- Постійне прослуховування аудіопотоку з мікрофона з активацією за голосом через `webrtcvad` (без ключового слова).
- Розпізнавання мовлення (STT) у реальному часі з підтримкою української мови (`uk-UA`).
- Обробка текстових запитів через LLM (Gemini API або Ollama).
- Синтез мовлення (TTS) із природним звучанням.
- Інтеграція з існуючим текстовим чатом через UI (веб або десктоп).
- Два режими роботи:
  - **Режим 1 (висока якість)**: Google Cloud STT/TTS + Gemini API для максимальної точності, швидкості (< 3 сек затримки) та природної взаємодії.
  - **Режим 2 (безкоштовний, офлайн)**: Whisper + Ollama + gTTS/Bark для роботи без інтернету та API-ключів.

**Мови**:

- Основна: українська (`uk-UA`).
- Додаткові (опціонально): англійська (`en-US`), російська (`ru-RU`).

**Платформи**:

- Інтеграція в текстовий чат (веб, десктоп, мобільний додаток).
- Сумісність із Python-бекендом (PyAudio, `webrtcvad`) та JavaScript-фронтендом (для вебверсії).

**Режим роботи**:

- Постійне прослуховування з активацією за голосом.
- Автоматична зупинка запису після 3 секунд тиші.
- Увімкнення/вимкнення через UI або голосові команди (“зупини”, “вимкни”).

-----

### 2. Технічні вимоги

#### 2.1. Компоненти системи

1. **Модуль розпізнавання мовлення (STT)**:
- **Режим 1: Google Cloud Speech-to-Text**:
  - API: `speech.googleapis.com`.
  - Методи:
    - `StreamingRecognize`: Потокове розпізнавання для реального часу.
    - `Recognize`: Синхронне розпізнавання (резерв для коротких аудіо).
  - Налаштування:
    - Формат: LINEAR16 (16-біт PCM).
    - Частота: 16000 Hz.
    - Мова: `uk-UA`.
    - `enable_automatic_punctuation: true`.
    - Модель: `default` або `phone_call` (для шумного аудіо).
  - Вимоги:
    - Точність: ≥ 90% (чітке аудіо), ≥ 80% (шумне).
    - Затримка: < 1 сек для першого результату.
- **Режим 2: Whisper**:
  - Модель: `large-v3` (або `base` для слабких пристроїв dirigir: /home/user/Документи/ТЗ для плагіна голосового асистента.docx слабкого обладнання).
  - Налаштування:
    - Формат: WAV, 16000 Hz.
    - Мова: `uk`.
  - Вимоги:
    - Точність: ≥ 80-90% (чітке аудіо), ≥ 60-70% (шумне).
    - Затримка: < 2 сек на GPU, < 10 сек на CPU.
  - Залежності: `openai-whisper`.
2. **Модуль обробки запитів (LLM)**:
- **Режим 1: Gemini API**:
  - API: Google AI Studio/Vertex AI (наприклад, `gemini-pro`).
  - Налаштування:
    - HTTP-запити для обробки тексту.
    - Контекст: збереження до 10 попередніх повідомлень.
  - Вимоги:
    - Час відповіді: < 2 сек для запитів до 50 слів.
    - Форматування: природний текст для TTS.
- **Режим 2: Ollama**:
  - Модель: Mistral 7B або Llama-2 (локально).
  - Налаштування:
    - Локальний сервер: `http://localhost:11434`.
  - Вимоги:
    - Час відповіді: < 3 сек на GPU, < 10 сек на CPU.
    - Підтримка української мови.
3. **Модуль синтезу мовлення (TTS)**:
- **Режим 1: Google Cloud Text-to-Speech**:
  - API: `texttospeech.googleapis.com`.
  - Методи:
    - `SynthesizeSpeech`: Для коротких текстів (< 500 символів).
    - `StreamingSynthesize`: Для реального часу.
    - `SynthesizeLongAudio`: Для текстів > 5000 символів.
    - `ListVoices`: Для вибору голосу (`uk-UA-Wavenet-A`).
  - Налаштування:
    - Формат: LINEAR16 (або MP3).
    - Частота: 24000 Hz.
    - SSML: для інтонацій (`<prosody>`, `<break>`).
  - Вимоги:
    - Затримка: < 1 сек для коротких текстів.
    - Природність: Wavenet-голоси.
- **Режим 2: gTTS або Bark**:
  - **gTTS**:
    - Безкоштовний через Google Translate.
    - Формат: MP3.
    - Затримка: ~1-2 сек.
    - Обмеження: без SSML, середня природність.
  - **Bark**:
    - Модель: `suno/bark-small` (офлайн).
    - Формат: WAV.
    - Затримка: ~2-5 сек на GPU.
    - Обмеження: обмежена підтримка української, середня природність.
  - Залежності: `gtts`, `suno-bark`.
4. **Модуль обробки аудіо (VAD)**:
- Бібліотека: `webrtcvad`.
- Налаштування:
  - Режим агресивності: 3.
  - Мінімальна тривалість мовлення: 0.5 сек.
  - Таймаут тиші: 3 сек.
- Вимоги:
  - Точність виявлення: ≥ 95%.
  - Буферизація: 0.5 сек аудіо перед активацією.
5. **Інтерфейс користувача (UI)**:
- Елементи:
  - Кнопка: увімкнення/вимкнення голосового режиму.
  - Індикатор стану: “Слухає”, “Обробляє”, “Відповідає”.
  - Текстове поле: розпізнаний текст і відповіді.
- Технології:
  - Веб: JavaScript, WebSocket.
  - Десктоп: Tkinter/PyQt.
- Вимоги:
  - Адаптивний дизайн.
  - Підтримка голосових команд (“зупини”, “вимкни”).

#### 2.2. Архітектура плагіну

- **Бекенд**:
  - Python 3.8+.
  - Модулі: `pyaudio`, `webrtcvad`, `google-cloud-speech`, `google-cloud-texttospeech`, `openai-whisper`, `gtts`, `suno-bark`, `requests`, `pygame`.
  - Асинхронна обробка: `queue.Queue`, `threading`.
  - Локальне збереження аудіо: тимчасові WAV-файли для дебагу.
- **Фронтенд**:
  - JavaScript (WebSocket/HTTP API) або Python GUI (Tkinter/PyQt).
- **API**:
  - Режим 1: Google Cloud STT/TTS (`speech.googleapis.com`, `texttospeech.googleapis.com`), Gemini API.
  - Режим 2: Whisper (локально), Ollama (`localhost:11434`), gTTS/Bark.
- **Операції для довгих текстів**:
  - Google TTS: `SynthesizeLongAudio` з `google.longrunning.Operations` (`GetOperation`, `WaitOperation`).

#### 2.3. Технічні характеристики

- **Формат аудіо**:
  - STT: 16-біт PCM, 16000 Hz.
  - TTS: LINEAR16/MP3, 24000 Hz.
- **Затримка**:
  - Режим 1: < 3 сек (STT + LLM + TTS).
  - Режим 2: < 3 сек на GPU, < 10 сек на CPU.
- **Платформи**:
  - Веб: Chrome, Edge.
  - Десктоп: Windows, Linux, macOS.
- **Апаратне забезпечення (для Режиму 2)**:
  - GPU: NVIDIA RTX 3060+ (рекомендується для Whisper large-v3, Bark).
  - CPU: 8+ ядер (для базової роботи).
  - RAM: ≥ 16 ГБ (для Ollama).

-----

### 3. Функціональні вимоги

1. **Режим “Завжди увімкнено”**:
- Постійне прослуховування через PyAudio + `webrtcvad`.
- Автоматична зупинка після 3 секунд тиші.
- Буферизація: 0.5 сек аудіо.
2. **Обробка аудіо**:
- Запис: 16-біт PCM, 16000 Hz.
- Фільтрація шуму через VAD (режим 3).
- Збереження: у пам’яті або тимчасових WAV-файлах.
3. **Розпізнавання мовлення (STT)**:
- **Режим 1**: Google STT (`StreamingRecognize`, `uk-UA`, `enable_automatic_punctuation`).
- **Режим 2**: Whisper (`large-v3`, `uk`).
- Обробка помилок: до 3 спроб, стандартна відповідь (“Не зрозумів”).
4. **Обробка запитів (LLM)**:
- **Режим 1**: Gemini API (HTTP-запити, контекст до 10 повідомлень).
- **Режим 2**: Ollama (Mistral 7B, локальний сервер).
- Форматування: природний текст для TTS.
5. **Синтез мовлення (TTS)**:
- **Режим 1**: Google TTS (`SynthesizeSpeech`, `StreamingSynthesize`, `uk-UA-Wavenet-A`, SSML).
- **Режим 2**: gTTS (`uk`, MP3) або Bark (`suno/bark-small`, WAV).
- Відтворення: PyAudio (десктоп) або `AudioContext` (веб).
6. **Людська взаємодія**:
- Затримка: < 3 сек.
- Інтонація: SSML (Режим 1) або базові паузи (Режим 2).
- Голосові команди: “зупини”, “вимкни”, “продовж”.
- Контекст: збереження діалогу.

-----

### 4. Інтеграція з існуючим чатом

1. **Точка входу**:
- Python-бекенд із WebSocket/HTTP API.
- JavaScript-фронтенд для вебверсії.
2. **UI інтеграція**:
- Кнопка: “Голосовий режим”.
- Індикатор стану: анімація (“Слухає”, “Обробляє”, “Відповідає”).
- Текстове поле: розпізнаний текст і відповіді.
- Синхронізація: голосові запити в текстовій історії чату.
3. **Контекст**:
- JSON-збереження діалогу (до 10 повідомлень).
- Відновлення сесії після перезапуску.

-----

### 5. Налаштування та залежності

1. **Режим 1: Google Cloud**:
- Проєкт у [Google Cloud Console](https://console.cloud.google.com/).
- API: `speech.googleapis.com`, `texttospeech.googleapis.com`.
- JSON-креденшіали: `GOOGLE_APPLICATION_CREDENTIALS`.
- Gemini API: [Google AI Studio](https://aistudio.google.com/).
2. **Режим 2: Безкоштовний офлайн**:
- Whisper: `large-v3` ([GitHub](https://github.com/openai/whisper)).
- Ollama: Mistral 7B ([GitHub](https://github.com/ollama/ollama)).
- gTTS: [GitHub](https://github.com/pndurette/gTTS).
- Bark: [GitHub](https://github.com/suno-ai/bark).
3. **Залежності**:
   
   ```bash
   pip install pyaudio webrtcvad google-cloud-speech google-cloud-texttospeech openai-whisper gtts suno-bark requests pygame
   ```
4. **Середовище**:
- Python 3.8+.
- Браузери: Chrome, Edge.
- ОС: Windows, Linux, macOS.

-----

### 6. Вимоги до продуктивності

- **Затримка**:
  - Режим 1: < 3 сек (STT + LLM + TTS).
  - Режим 2: < 3 сек на GPU, < 10 сек на CPU.
- **Ресурси**:
  - Режим 1: Інтернет ≥ 10 Мбіт/с.
  - Режим 2: GPU (RTX 3060+), CPU (8+ ядер), RAM ≥ 16 ГБ.
- **Надійність**:
  - Обробка помилок: 3 спроби, стандартні відповіді.
  - Кешування TTS: для економії API-запитів.

-----

### 7. Тестування та дебаг

1. **Тестові сценарії**:
- Точність STT: ≥ 90% (Режим 1), ≥ 80% (Режим 2) для чіткого аудіо.
- Шумне аудіо: ≥ 80% (Режим 1), ≥ 60% (Режим 2).
- TTS: природність (суб’єктивна оцінка).
- Голосові команди: “зупини”, “вимкни”.
- Довгі тексти: `SynthesizeLongAudio` (Режим 1).
2. **Логування**:
- Аудіофайли: для аналізу помилок.
- Логи API: `logs/assistant.log`.
3. **Метрики**:
- Час реакції: < 3 сек.
- Успішність запитів: ≥ 95%.

-----

### 8. Терміни та етапи розробки

1. **Етап 1: Налаштування (1 тиждень)**:
- Google Cloud API, Gemini API, Whisper, Ollama.
- Встановлення залежностей.
2. **Етап 2: Розробка бекенду (2 тижні)**:
- Інтеграція STT/TTS/LLM (обидва режими).
- Реалізація VAD і потокового режиму.
3. **Етап 3: Інтеграція з чатом (1 тиждень)**:
- UI, WebSocket/HTTP API.
- Синхронізація текстового та голосового режимів.
4. **Етап 4: Тестування та дебаг (1 тиждень)**:
- Тестування в різних умовах (шум, акценти).
- Оптимізація затримок.
5. **Загальний термін**: 5 тижнів.

-----

### 9. Додаткові вдосконалення

- **Оптимізація**:
  - Кешування TTS-відповідей.
  - Потокові режими (`StreamingRecognize`, `StreamingSynthesize`).
  - GPU-прискорення для Whisper/Ollama/Bark.
- **Розширюваність**:
  - Додавання мов (`en-US`, `ru-RU`).
  - Резервні API (Whisper/gTTS для Режиму 1).
- **Безпека**:
  - Захист API-ключів: змінні середовища.
  - Шифрування WebSocket.

-----

### 10. Документація та підтримка

1. **Документація**:
- Інструкція: встановлення, налаштування API, запуск.
- Опис методів: `StreamingRecognize`, `SynthesizeSpeech`, `StreamingSynthesize`, Whisper, Ollama.
- Приклади SSML і голосових команд.
2. **Підтримка**:
- Логи: `logs/assistant.log`.
- Дебаг: аудіофайли, API-відповіді.

-----

### 11. Ризики та обмеження

- **Режим 1**:
  - Обмеження: 60 хв STT, 4 МБ TTS/місяць.
  - Потреба в інтернеті.
  - Приватність: хмарна обробка.
- **Режим 2**:
  - Точність STT: нижча (~80-90%).
  - TTS: менш природний (gTTS/Bark).
  - Високі вимоги до GPU/CPU.
- **Рішення**:
  - Перемикання між режимами в налаштуваннях.
  - Кешування для економії API-запитів.
  - Тестування VAD у шумних умовах.

-----

### 12. Очікуваний результат

Плагін, який інтегрується в текстовий чат і забезпечує:

- **Режим 1**: Висока якість (Google STT/TTS + Gemini), затримка < 3 сек, точність STT ≥ 90%, природне звучання.
- **Режим 2**: Безкоштовний офлайн-режим (Whisper + Ollama + gTTS/Bark), затримка < 3 сек на GPU, точність STT ≥ 80%.
- UI: кнопка, індикатор, текстове поле.
- Синхронізація: голосові запити в текстовій історії.
- Людська взаємодія: контекст, інтонація, голосові команди.

-----

### 13. Посилання на API

1. **Режим 1**:
- Google Cloud Speech-to-Text: [Enable API](https://console.cloud.google.com/apis/library/speech.googleapis.com)
- Google Cloud Text-to-Speech: [Enable API](https://console.cloud.google.com/apis/library/texttospeech.googleapis.com)
- Gemini API: [Google AI Studio](https://aistudio.google.com/)
2. **Режим 2**:
- Whisper: [GitHub](https://github.com/openai/whisper)
- Ollama: [GitHub](https://github.com/ollama/ollama)
- gTTS: [GitHub](https://github.com/pndurette/gTTS)
- Bark: [GitHub](https://github.com/suno-ai/bark)

-----

Якщо потрібні додаткові приклади коду, деталі UI чи оптимізація для конкретного апаратного забезпечення, повідомте!