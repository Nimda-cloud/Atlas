#!/usr/bin/env python3
"""
Atlas Code Status Reporter - –ì–µ–Ω–µ—Ä—É—î –∑–≤—ñ—Ç –ø—Ä–æ —Å—Ç–∞–Ω –∫–æ–¥—É –ø—Ä–æ–µ–∫—Ç—É
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É –ø—Ä–æ–≥—Ä–µ—Å—É —É –≤–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—ñ –ø–æ–º–∏–ª–æ–∫ –∫–æ–¥—É
"""

import json
import logging
import subprocess
import sys
from collections import Counter, defaultdict
from datetime import datetime
from pathlib import Path

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()],
)
logger = logging.getLogger("AtlasCodeReporter")

# –ö–∞—Ç–µ–≥–æ—Ä—ñ—ó –ø–æ–º–∏–ª–æ–∫
ERROR_CATEGORIES = {
    "F": "Flake8 –ø–æ–º–∏–ª–∫–∏",
    "E": "–°—Ç–∏–ª—å–æ–≤—ñ –ø–æ–º–∏–ª–∫–∏",
    "W": "–ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è",
    "SIM": "–°–ø—Ä–æ—â–µ–Ω–Ω—è –∫–æ–¥—É",
    "B": "–ü–æ–º–∏–ª–∫–∏ –∫–æ–Ω—Ç—Ä–æ–ª—é –±–∞–≥—ñ–≤",
    "I": "–Ü–º–ø–æ—Ä—Ç–∏",
    "N": "–ù–∞–π–º–µ–Ω—É–≤–∞–Ω–Ω—è",
    "C": "–°–∫–ª–∞–¥–Ω—ñ—Å—Ç—å",
    "D": "–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è",
    "PLR": "PyLint",
    "TRY": "–û–±—Ä–æ–±–∫–∞ –≤–∏–Ω—è—Ç–∫—ñ–≤",
}

# –ö—Ä–∏—Ç–∏—á–Ω—ñ —Ç–∏–ø–∏ –ø–æ–º–∏–ª–æ–∫, —è–∫—ñ –≤–∞—Ä—Ç–æ –≤–∏–ø—Ä–∞–≤–∏—Ç–∏ –ø–µ—Ä—à–æ—á–µ—Ä–≥–æ–≤–æ
CRITICAL_ERRORS = ["F821", "B904", "E402", "F811", "SIM102", "SIM117"]


def run_ruff_check(select=None):
    """–í–∏–∫–æ–Ω–∞–Ω–Ω—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –∫–æ–¥—É –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é Ruff."""
    cmd = ["ruff", "check", "--output-format=json"]

    if select:
        cmd.append(f"--select={select}")

    cmd.append(".")

    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0 and result.stdout:
            return json.loads(result.stdout)
        else:
            return []
    except Exception as ex:
        logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫—É Ruff: {ex}")
        return []


def categorize_errors(errors):
    """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑—É—î –ø–æ–º–∏–ª–∫–∏ –∑–∞ —Ç–∏–ø–∞–º–∏ —Ç–∞ —Ñ–∞–π–ª–∞–º–∏."""
    error_types = Counter()
    errors_by_category = defaultdict(Counter)
    errors_by_file = defaultdict(Counter)
    critical_errors = Counter()

    for error in errors:
        error_code = error.get("code", "")
        filename = error.get("filename", "")

        error_types[error_code] += 1

        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑—É—î–º–æ –∑–∞ –ø—Ä–µ—Ñ—ñ–∫—Å–æ–º –∫–æ–¥—É
        category_prefix = "".join(c for c in error_code if not c.isdigit())
        category_name = ERROR_CATEGORIES.get(category_prefix, "–Ü–Ω—à–µ")
        errors_by_category[category_name][error_code] += 1

        # –†–∞—Ö—É—î–º–æ –ø–æ–º–∏–ª–∫–∏ –ø–æ —Ñ–∞–π–ª–∞—Ö
        errors_by_file[filename][error_code] += 1

        # –†–∞—Ö—É—î–º–æ –∫—Ä–∏—Ç–∏—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏
        if error_code in CRITICAL_ERRORS:
            critical_errors[error_code] += 1

    return {
        "error_types": error_types,
        "errors_by_category": errors_by_category,
        "errors_by_file": errors_by_file,
        "critical_errors": critical_errors,
    }


def generate_report(errors_data):
    """–ì–µ–Ω–µ—Ä—É—î –∑–≤—ñ—Ç —ñ–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ—é –ø–æ–º–∏–ª–æ–∫."""

    if not errors_data.get("error_types"):
        logger.info("üéâ –ü–æ–º–∏–ª–æ–∫ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ! –ö–æ–¥ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º.")
        return

    error_types = errors_data["error_types"]
    errors_by_category = errors_data["errors_by_category"]
    errors_by_file = errors_data["errors_by_file"]
    critical_errors = errors_data["critical_errors"]

    total_errors = sum(error_types.values())

    report = []
    report.append(
        f"üìä –ó–í–Ü–¢ –°–¢–ê–ù–£ –ö–û–î–£ ATLAS ({datetime.now().strftime('%Y-%m-%d %H:%M')})"
    )
    report.append("=" * 70)
    report.append(f"üìà –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–º–∏–ª–æ–∫: {total_errors}")

    # –ö—Ä–∏—Ç–∏—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏
    if critical_errors:
        report.append("\n‚ö†Ô∏è  –ö–†–ò–¢–ò–ß–ù–Ü –ü–û–ú–ò–õ–ö–ò, –Ø–ö–Ü –ü–û–¢–†–Ü–ë–ù–û –í–ò–ü–†–ê–í–ò–¢–ò:")
        report.append("-" * 50)
        for code, count in critical_errors.most_common():
            report.append(f"  {code}: {count} –≤–∏–ø–∞–¥–∫—ñ–≤")

    # –ü–æ–º–∏–ª–∫–∏ –∑–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è–º–∏
    report.append("\nüìã –†–û–ó–ü–û–î–Ü–õ –ü–û–ú–ò–õ–û–ö –ó–ê –ö–ê–¢–ï–ì–û–†–Ü–Ø–ú–ò:")
    report.append("-" * 50)
    for category, codes in sorted(
        errors_by_category.items(), key=lambda x: sum(x[1].values()), reverse=True
    ):
        category_total = sum(codes.values())
        percentage = (category_total / total_errors) * 100
        report.append(f"  {category}: {category_total} –ø–æ–º–∏–ª–æ–∫ ({percentage:.1f}%)")

        # –î–µ—Ç–∞–ª—ñ –¥–ª—è –∫–æ–∂–Ω–æ—ó –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó (—Ç–æ–ø-5)
        for code, count in codes.most_common(5):
            report.append(f"    - {code}: {count} –ø–æ–º–∏–ª–æ–∫")

        if len(codes) > 5:
            report.append(f"    - ... —Ç–∞ —â–µ {len(codes) - 5} —Ç–∏–ø—ñ–≤")

    # –§–∞–π–ª–∏ –∑ –Ω–∞–π–±—ñ–ª—å—à–æ—é –∫—ñ–ª—å–∫—ñ—Å—Ç—é –ø–æ–º–∏–ª–æ–∫ (—Ç–æ–ø-10)
    report.append("\nüìÅ –§–ê–ô–õ–ò –ó –ù–ê–ô–ë–Ü–õ–¨–®–û–Æ –ö–Ü–õ–¨–ö–Ü–°–¢–Æ –ü–û–ú–ò–õ–û–ö:")
    report.append("-" * 50)
    for filename, codes in sorted(
        errors_by_file.items(), key=lambda x: sum(x[1].values()), reverse=True
    )[:10]:
        file_path = Path(filename)
        total_file_errors = sum(codes.values())
        report.append(f"  {file_path.name}: {total_file_errors} –ø–æ–º–∏–ª–æ–∫")

        # –¢–æ–ø-3 —Ç–∏–ø–∏ –ø–æ–º–∏–ª–æ–∫ –¥–ª—è —Ü—å–æ–≥–æ —Ñ–∞–π–ª—É
        for code, count in codes.most_common(3):
            report.append(f"    - {code}: {count}")

    # –ó–∞–≥–∞–ª—å–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    report.append("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:")
    report.append("-" * 50)

    if critical_errors:
        report.append("  1. –£—Å—É–Ω—å—Ç–µ –∫—Ä–∏—Ç–∏—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏ –ø–µ—Ä—à–æ—á–µ—Ä–≥–æ–≤–æ:")
        for code in critical_errors:
            if code == "F821":
                report.append("     - F821: –î–æ–¥–∞–π—Ç–µ –≤—Å—ñ –≤—ñ–¥—Å—É—Ç–Ω—ñ —ñ–º–ø–æ—Ä—Ç–∏")
            elif code == "B904":
                report.append(
                    "     - B904: –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ 'raise ... from err' –≤ –±–ª–æ–∫–∞—Ö except"
                )
            elif code == "SIM102" or code == "SIM117":
                report.append(
                    "     - SIM102/SIM117: –°–ø—Ä–æ—Å—Ç—ñ—Ç—å –≤–∫–ª–∞–¥–µ–Ω—ñ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∏ if/with"
                )
            elif code == "E402":
                report.append("     - E402: –ü–µ—Ä–µ–º—ñ—Å—Ç—ñ—Ç—å –≤—Å—ñ —ñ–º–ø–æ—Ä—Ç–∏ –Ω–∞ –ø–æ—á–∞—Ç–æ–∫ —Ñ–∞–π–ª—É")

    report.append("  2. –ó–∞–ø—É—Å—Ç—ñ—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–π —Ñ—ñ–∫—Å–µ—Ä –¥–ª—è —Ä–æ–∑–≤'—è–∑–∞–Ω–Ω—è —Ç–∏–ø–æ–≤–∏—Ö –ø—Ä–æ–±–ª–µ–º:")
    report.append("     python scripts/atlas_code_fixer.py")

    report.append("  3. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ pre-commit —Ö—É–∫–∏ –¥–ª—è –∑–∞–ø–æ–±—ñ–≥–∞–Ω–Ω—è –Ω–æ–≤–∏—Ö –ø–æ–º–∏–ª–æ–∫:")
    report.append("     pre-commit install")

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–≤—ñ—Ç —É —Ñ–∞–π–ª
    report_path = Path("reports/code_quality_report.txt")
    report_path.parent.mkdir(exist_ok=True)

    with open(report_path, "w", encoding="utf-8") as f:
        f.write("\n".join(report))

    logger.info(f"üìÑ –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {report_path}")

    # –í–∏–≤–æ–¥–∏–º–æ –∑–≤—ñ—Ç –≤ –∫–æ–Ω—Å–æ–ª—å
    print("\n".join(report))


def save_errors_history(errors_data):
    """–ó–±–µ—Ä—ñ–≥–∞—î —ñ—Å—Ç–æ—Ä—ñ—é –ø–æ–º–∏–ª–æ–∫ –¥–ª—è –≤—ñ–¥—Å—Ç–µ–∂–µ–Ω–Ω—è –ø—Ä–æ–≥—Ä–µ—Å—É."""
    history_path = Path("reports/errors_history.json")
    history_path.parent.mkdir(exist_ok=True)

    # –ì–æ—Ç—É—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è
    error_counts = {
        "date": datetime.now().isoformat(),
        "total": sum(errors_data["error_types"].values()),
        "by_category": {
            category: sum(codes.values())
            for category, codes in errors_data["errors_by_category"].items()
        },
        "critical": sum(errors_data["critical_errors"].values()),
    }

    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –ø–æ–ø–µ—Ä–µ–¥–Ω—é —ñ—Å—Ç–æ—Ä—ñ—é
    history = []
    if history_path.exists():
        try:
            with open(history_path, "r", encoding="utf-8") as f:
                history = json.load(f)
        except json.JSONDecodeError:
            logger.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç–∏ —Ñ–∞–π–ª —ñ—Å—Ç–æ—Ä—ñ—ó, —Å—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π")

    # –î–æ–¥–∞—î–º–æ –Ω–æ–≤—ñ –¥–∞–Ω—ñ
    history.append(error_counts)

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –æ–Ω–æ–≤–ª–µ–Ω—É —ñ—Å—Ç–æ—Ä—ñ—é
    with open(history_path, "w", encoding="utf-8") as f:
        json.dump(history, f, indent=2)

    logger.info(f"üìä –Ü—Å—Ç–æ—Ä—ñ—é –ø–æ–º–∏–ª–æ–∫ –æ–Ω–æ–≤–ª–µ–Ω–æ —É {history_path}")


def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è."""
    logger.info("üîç –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª—ñ–∑—É –∫–æ–¥—É Atlas...")

    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –º–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ñ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó
    if not Path("pyproject.toml").exists():
        logger.error("‚ùå –ó–∞–ø—É—Å—Ç—ñ—Ç—å —Å–∫—Ä–∏–ø—Ç –∑ –∫–æ—Ä–µ–Ω–µ–≤–æ—ó –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –ø—Ä–æ—î–∫—Ç—É Atlas")
        sys.exit(1)

    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫—É Ruff
    logger.info("üìä –ó–±–∏—Ä–∞—î–º–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–º–∏–ª–æ–∫ –∫–æ–¥—É...")
    errors = run_ruff_check()

    # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –ø–æ–º–∏–ª–∫–∏
    errors_data = categorize_errors(errors)

    # –ì–µ–Ω–µ—Ä—É—î–º–æ –∑–≤—ñ—Ç
    generate_report(errors_data)

    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —ñ—Å—Ç–æ—Ä—ñ—é
    save_errors_history(errors_data)

    logger.info("‚úÖ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    main()
